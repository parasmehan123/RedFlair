{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/parasmehan123/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/parasmehan123/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/parasmehan123/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "string.punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from copy import deepcopy as dp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.externals import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rahul Gandhi resigns as President of Congress</td>\n",
       "      <td>1120</td>\n",
       "      <td>c8lydy</td>\n",
       "      <td>https://www.aninews.in/news/national/general-n...</td>\n",
       "      <td>413</td>\n",
       "      <td>1.562175e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is legalization of marijuana in India ever goi...</td>\n",
       "      <td>81</td>\n",
       "      <td>bvvre5</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/bvvre5...</td>\n",
       "      <td>124</td>\n",
       "      <td>1.559497e+09</td>\n",
       "      <td>As a cannabis enthusiast (stoner, pothead), it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was searching for something and I stumbled u...</td>\n",
       "      <td>314</td>\n",
       "      <td>cd3xmx</td>\n",
       "      <td>https://i.imgur.com/FefhpHc.jpg</td>\n",
       "      <td>109</td>\n",
       "      <td>1.563145e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emperors of Extraction: The Mughals did not ma...</td>\n",
       "      <td>35</td>\n",
       "      <td>cdargd</td>\n",
       "      <td>https://www.dailyo.in/politics/emperors-of-ext...</td>\n",
       "      <td>7</td>\n",
       "      <td>1.563181e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chennaite here. Is there any way for us to mak...</td>\n",
       "      <td>83</td>\n",
       "      <td>c22c7k</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/c22c7k...</td>\n",
       "      <td>30</td>\n",
       "      <td>1.560894e+09</td>\n",
       "      <td>It's crazy how they aren't even talking about ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0      Rahul Gandhi resigns as President of Congress   1120  c8lydy   \n",
       "1  Is legalization of marijuana in India ever goi...     81  bvvre5   \n",
       "2  I was searching for something and I stumbled u...    314  cd3xmx   \n",
       "3  Emperors of Extraction: The Mughals did not ma...     35  cdargd   \n",
       "4  Chennaite here. Is there any way for us to mak...     83  c22c7k   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0  https://www.aninews.in/news/national/general-n...        413  1.562175e+09   \n",
       "1  https://www.reddit.com/r/india/comments/bvvre5...        124  1.559497e+09   \n",
       "2                    https://i.imgur.com/FefhpHc.jpg        109  1.563145e+09   \n",
       "3  https://www.dailyo.in/politics/emperors-of-ext...          7  1.563181e+09   \n",
       "4  https://www.reddit.com/r/india/comments/c22c7k...         30  1.560894e+09   \n",
       "\n",
       "                                                body  flair  \n",
       "0                                                NaN      0  \n",
       "1  As a cannabis enthusiast (stoner, pothead), it...      0  \n",
       "2                                                NaN      0  \n",
       "3                                                NaN      0  \n",
       "4  It's crazy how they aren't even talking about ...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=df1['title'].tolist()\n",
    "body=df1['body'].tolist()\n",
    "url=df1['url'].tolist()\n",
    "y=df1['flair'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stopwords_removal(tokens):\n",
    "    stop_words = list(stopwords.words(\"english\"))\n",
    "    filtered_sentence = [w for w in tokens if not w in stop_words]              \n",
    "    final=' '.join(filtered_sentence)\n",
    "    return final\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    obj=str.maketrans('', '',string.punctuation)\n",
    "    answer=text.translate(obj)\n",
    "    return answer\n",
    "\n",
    "def simple_lemma(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered=[lemmatizer.lemmatize(word) for word in data.split()]\n",
    "    text = ' '.join(filtered)\n",
    "    return text\n",
    "\n",
    "def pre_process(y,flag):\n",
    "    x=deepcopy(y)\n",
    "    for i in range(len(x)):\n",
    "        if str([i])!='nan':\n",
    "            if flag:\n",
    "                x[i]=x[i].split('/')\n",
    "                x[i]=' '.join(x[i])\n",
    "            x[i]=simple_lemma(remove_punctuation(stopwords_removal(word_tokenize(str(x[i]).lower()))))\n",
    "        else:\n",
    "            x[i]=''\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rahul Gandhi resigns as President of Congress',\n",
       " 'Is legalization of marijuana in India ever going to be a serious political issue during our lifetime, or are we going to be criminals forever?',\n",
       " 'I was searching for something and I stumbled upon my 2nd std papers! 9Â¾/10 bois, AMA ðŸ˜‚',\n",
       " 'Emperors of Extraction: The Mughals did not make India rich. Claims of their welfarism only buttress a political agenda',\n",
       " 'Chennaite here. Is there any way for us to make the political parties talk about building ponds and reservoirs?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_clean=pre_process(title,False)\n",
    "body_clean=pre_process(body,False)\n",
    "url_clean=pre_process(url,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nan',\n",
       " 'cannabis enthusiast stoner pothead pain see many country across world taking issue seriously re reduced criminal status purchasing illegal weed questionable source expect india take debate anytime soon',\n",
       " 'nan',\n",
       " 'nan',\n",
       " 's crazy nt even talking even opposition ca nt go like p situation grim chennai somehow sound worse medium guess could say dire situation nt case chennai depends locality ground water run almost run locality every year situation gradually worsening guess']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_clean[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier,X_train,y_train,X_test,y_test):\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_train_pred=classifier.predict(X_train)\n",
    "    y_test_pred=classifier.predict(X_test)\n",
    "    return accuracy_score(y_train,y_train_pred),accuracy_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mst=(np.random.rand(len(df1)) < 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test(x):\n",
    "    X_train=[]\n",
    "    X_test=[]\n",
    "    y1_train=[]\n",
    "    y1_test=[]\n",
    "    for i in range(len(mst)):\n",
    "        if mst[i]:\n",
    "            X_train.append(x[i])\n",
    "            y1_train.append(y[i])\n",
    "        else:\n",
    "            X_test.append(x[i])\n",
    "            y1_test.append(y[i])\n",
    "    tf = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "    X1_train = tf.fit_transform(X_train)  \n",
    "    X1_test = tf.transform(X_test)\n",
    "    \n",
    "    clf1=GridSearchCV(SVC(gamma='scale'),{'decision_function_shape':['ovo','ovr'],},cv=5,iid=False)\n",
    "    print(train(clf1,X1_train,y1_train,X1_test,y1_test))\n",
    "    \n",
    "    clf2=GridSearchCV(KNeighborsClassifier(),{'n_neighbors':[2,5,7]},cv=5,iid=False)\n",
    "    print(train(clf2,X1_train,y1_train,X1_test,y1_test))\n",
    "    \n",
    "    clf3=GridSearchCV(DecisionTreeClassifier(random_state=0),{'criterion':['gini','entropy']},cv=5,iid=False)\n",
    "    print(train(clf3,X1_train,y1_train,X1_test,y1_test))\n",
    "    \n",
    "    clf4=GridSearchCV(LogisticRegression(random_state=0),{'solver':['newton-cg', 'lbfgs','sag', 'saga','lbfgs'],'multi_class':['multinomial'],'max_iter':[200,250,300]},cv=5,iid=False)\n",
    "    print(train(clf4,X1_train,y1_train,X1_test,y1_test))\n",
    "    \n",
    "    clf5=GridSearchCV(RandomForestClassifier(random_state=0),{'n_estimators':[10,50,100,150],'criterion':['gini','entropy']},cv=5,iid=False)\n",
    "    print(train(clf5,X1_train,y1_train,X1_test,y1_test))\n",
    "    \n",
    "    clf6=GridSearchCV(xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42),{'max_depth':[2,3],'learning_rate':[0.1,0.15,0.2]},cv=5,iid=False)\n",
    "    print(train(clf6,X1_train,y1_train,X1_test,y1_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8760217983651226, 0.6467236467236467)\n",
      "(0.5429155313351499, 0.34472934472934474)\n",
      "(0.920299727520436, 0.5641025641025641)\n",
      "(0.7922343324250681, 0.6410256410256411)\n",
      "(0.920299727520436, 0.6125356125356125)\n",
      "(0.7316076294277929, 0.5783475783475783)\n"
     ]
    }
   ],
   "source": [
    "train_test(title_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.26634877384196187, 0.27635327635327633)\n",
      "(0.21934604904632152, 0.19658119658119658)\n",
      "(0.26634877384196187, 0.2706552706552707)\n",
      "(0.2622615803814714, 0.2792022792022792)\n",
      "(0.26634877384196187, 0.2678062678062678)\n",
      "(0.26430517711171664, 0.2564102564102564)\n"
     ]
    }
   ],
   "source": [
    "train_test(url_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7568119891008175, 0.4985754985754986)\n",
      "(0.27520435967302453, 0.21937321937321938)\n",
      "(0.7752043596730245, 0.5327635327635327)\n",
      "(0.6559945504087193, 0.5242165242165242)\n",
      "(0.7752043596730245, 0.5783475783475783)\n",
      "(0.7275204359673024, 0.603988603988604)\n"
     ]
    }
   ],
   "source": [
    "train_test(body_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9407356948228883, 0.717948717948718)\n",
      "(0.6907356948228883, 0.5441595441595442)\n",
      "(0.9550408719346049, 0.7549857549857549)\n",
      "(0.8807901907356949, 0.7435897435897436)\n",
      "(0.9550408719346049, 0.7863247863247863)\n",
      "(0.9250681198910081, 0.8176638176638177)\n"
     ]
    }
   ],
   "source": [
    "ti_bo=[]\n",
    "for i in range(len(title_clean)):\n",
    "    ti_bo.append(title_clean[i]+\" \"+body_clean[i])\n",
    "train_test(ti_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9455040871934605, 0.7264957264957265)\n",
      "(0.694141689373297, 0.5498575498575499)\n",
      "(0.9584468664850136, 0.7663817663817664)\n",
      "(0.8930517711171662, 0.7549857549857549)\n",
      "(0.9584468664850136, 0.7948717948717948)\n",
      "(0.9066757493188011, 0.811965811965812)\n"
     ]
    }
   ],
   "source": [
    "ti_bo_ur=[]\n",
    "for i in range(len(title_clean)):\n",
    "    ti_bo_ur.append(title_clean[i]+\" \"+body_clean[i]+\" \"+url_clean[i])\n",
    "train_test(ti_bo_ur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8072207084468664, 0.5441595441595442)\n",
      "(0.4019073569482289, 0.28774928774928776)\n",
      "(0.8228882833787466, 0.5584045584045584)\n",
      "(0.7173024523160763, 0.5641025641025641)\n",
      "(0.8228882833787466, 0.6068376068376068)\n",
      "(0.7084468664850136, 0.6125356125356125)\n"
     ]
    }
   ],
   "source": [
    "bo_ur=[]\n",
    "for i in range(len(body_clean)):\n",
    "    bo_ur.append(body_clean[i]+\" \"+url_clean[i])\n",
    "train_test(bo_ur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8876021798365122, 0.6552706552706553)\n",
      "(0.5381471389645777, 0.3418803418803419)\n",
      "(0.9291553133514986, 0.5754985754985755)\n",
      "(0.8072207084468664, 0.6609686609686609)\n",
      "(0.9291553133514986, 0.6410256410256411)\n",
      "(0.776566757493188, 0.5954415954415955)\n"
     ]
    }
   ],
   "source": [
    "ti_ur=[]\n",
    "for i in range(len(title_clean)):\n",
    "    ti_ur.append(title_clean[i]+\" \"+url_clean[i])\n",
    "train_test(ti_ur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=GridSearchCV(xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42),{'max_depth':[2,3],'learning_rate':[0.1,0.15,0.2]},cv=5,iid=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "X = tfidfconverter.fit_transform(ti_bo_ur).toarray()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=42, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'max_depth': [2, 3], 'learning_rate': [0.1, 0.15, 0.2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9263331500824629\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(X)\n",
    "print(accuracy_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ti_bo_ur,columns=['text']).to_csv('data_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
